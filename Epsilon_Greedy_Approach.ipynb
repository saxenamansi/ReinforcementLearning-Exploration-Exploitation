{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aHZi_-VX5M8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_approach(Q_values):\n",
        "  top_value = float(\"-inf\")\n",
        "  ties = []     # list to store index of the highest q-value actions\n",
        "  for i in range(len(Q_values)):\n",
        "    if Q_values[i] > top_value:     # check q_value of each action against the top value\n",
        "      top_value = Q_values[i]       # if it is higher than current top value, then reinitialise ties list and append this value to it\n",
        "      ties = []\n",
        "      ties.append(i)\n",
        "    elif Q_values[i] == top_value:\n",
        "      ties.append(i)                # if a tie is found, simply append the value to it\n",
        "  return np.random.choice(ties)     # break ties randomly"
      ],
      "metadata": {
        "id": "qKx06RVqYXSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reward_function(x):\n",
        "  return np.random.normal(x, 1)"
      ],
      "metadata": {
        "id": "v8L2qZ5sfwT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def realistic_Egreedy(qs_values, epsilon, num_actions, reward_function = reward_function):\n",
        "  Q_values = [0]*num_actions      # realistic initial values\n",
        "  actions = []\n",
        "  count_actions = [0]*num_actions\n",
        "  for stepsize in range(1, n+1):\n",
        "    e = np.random.random()\n",
        "    if e < epsilon:\n",
        "      i = np.random.randint(0, num_actions)      # choose random action with epsilon probability\n",
        "    else:\n",
        "      i = greedy_approach(Q_values)      #  choose greedily with 1-epsilon probability\n",
        "    actions.append(i)\n",
        "    count_actions[i] += 1\n",
        "    reward = reward_function(qs_values[i])\n",
        "    Q_values[i]  = Q_values[i] + (1/count_actions[i])*(reward - Q_values[i])  # incremental equation to update the estimated q-value\n",
        "  return actions"
      ],
      "metadata": {
        "id": "uHCpvB8ZfjE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimistic_Egreedy(qs_values, epsilon, num_actions, optimistic_val = 12, reward_function = reward_function):\n",
        "  Q_values = [optimistic_val]*num_actions     # optimistic initial values\n",
        "  actions = []\n",
        "  count_actions = [0]*num_actions\n",
        "  for stepsize in range(1, n+1):\n",
        "    e = np.random.random()\n",
        "    if e < epsilon:\n",
        "      i = np.random.randint(0,num_actions)      # choose random action with epsilon probability\n",
        "    else:\n",
        "      i = greedy_approach(Q_values)        #  choose greedily with 1-epsilon probability\n",
        "    actions.append(i)\n",
        "    count_actions[i] += 1\n",
        "    reward = reward_function(qs_values[i])\n",
        "    Q_values[i]  = Q_values[i] + (1/count_actions[i])*(reward - Q_values[i])    # incremental equation to update the estimated q-value\n",
        "  return actions"
      ],
      "metadata": {
        "id": "fpwZ9AV9KIJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = 0.1\n",
        "num_actions = 10\n",
        "n = 20\n",
        "\n",
        "count_real_Egreedy = [0]*n\n",
        "\n",
        "qs_values = np.random.normal(loc=0.0, scale=5.0, size=num_actions)\n",
        "optimal_action = np.random.choice(np.flatnonzero(qs_values == qs_values.max()))\n",
        "\n",
        "optimistic_Egreedy_actions = optimistic_Egreedy(qs_values, epsilon, num_actions)\n",
        "print(optimistic_Egreedy_actions)\n",
        "\n",
        "tmp_opt_Egreedy = list(map(int, optimistic_Egreedy_actions == optimal_action))\n",
        "print(tmp_opt_Egreedy)\n",
        "\n",
        "count_opt_Egreedy = np.add(count_real_Egreedy, tmp_opt_Egreedy)\n",
        "print(count_opt_Egreedy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj8TcDxnI401",
        "outputId": "9384eeed-5105-4ea9-8f12-e047f03e7b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 9, 1, 7, 2, 3, 4, 0, 6, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
            "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qs_values = np.random.normal(loc=0.0, scale=5.0, size=num_actions)\n",
        "optimal_action = np.random.choice(np.flatnonzero(qs_values == qs_values.max()))\n",
        "print(optimal_action)\n",
        "n = 20\n",
        "print(qs_values)\n",
        "\n",
        "print(realistic_Egreedy(qs_values, epsilon, num_actions))\n",
        "print(optimistic_Egreedy(qs_values, epsilon, num_actions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWz_Dr72Yc-Y",
        "outputId": "dd8ddcff-1b03-4893-9b34-d76a9ca14e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "[-1.53692098  0.38632918  0.04605652  7.81482604  7.29075316  2.06753857\n",
            "  5.30856027  7.19990296  8.42991882 -4.61044812]\n",
            "[3, 3, 3, 7, 7, 7, 3, 7, 7, 7, 3, 3, 9, 7, 7, 8, 8, 8, 8, 8]\n",
            "[0, 7, 2, 6, 8, 9, 4, 1, 5, 3, 3, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 dice problem"
      ],
      "metadata": {
        "id": "lWTW2YaWYU5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "quEfmwdSZCNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a reward function\n",
        "\n",
        "def dice_reward(action_num, prob):\n",
        "  p = np.random.random()\n",
        "  if action_num == 0 or p > prob:\n",
        "    reward = random.randint(1, 6)\n",
        "  elif p < prob:\n",
        "    if action_num == 1:\n",
        "      reward = 6\n",
        "    elif action_num == 2:\n",
        "      reward = 1\n",
        "  return reward"
      ],
      "metadata": {
        "id": "MAHJeB5aYmXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_actions = 3\n",
        "n = 5000\n",
        "prob = 0.1\n",
        "epsilon = 0.1"
      ],
      "metadata": {
        "id": "pbMh6WiWYvXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_approach(Q_values):\n",
        "  top_value = float(\"-inf\")\n",
        "  ties = []     # list to store index of the highest q-value actions\n",
        "  for i in range(len(Q_values)):\n",
        "    if Q_values[i] > top_value:     # check q_value of each action against the top value\n",
        "      top_value = Q_values[i]       # if it is higher than current top value, then reinitialise ties list and append this value to it\n",
        "      ties = []\n",
        "      ties.append(i)\n",
        "    elif Q_values[i] == top_value:\n",
        "      ties.append(i)                # if a tie is found, simply append the value to it\n",
        "  return np.random.choice(ties)     # break ties randomly"
      ],
      "metadata": {
        "id": "RC7ckDDzY_VR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimistic, Greedy\n",
        "\n",
        "def optimistic_greedy(num_actions = 3, optimistic_val = 7):\n",
        "  Q_values = [optimistic_val]*num_actions   # optimistic initial values\n",
        "  q1_vals = []\n",
        "  q2_vals = []\n",
        "  q3_vals = []\n",
        "  actions = []\n",
        "  count_actions = [0]*num_actions\n",
        "  for stepsize in range(1, n+1):\n",
        "    i = greedy_approach(Q_values)             # choose greedily, ie, choose the action with the highest q-value at each step\n",
        "    actions.append(i)\n",
        "    reward = dice_reward(i, prob)\n",
        "    count_actions[i] += 1\n",
        "    Q_values[i]  = Q_values[i] + (1/count_actions[i])*(reward - Q_values[i])    # incremental equation to update the estimated q-value\n",
        "    q1_vals.append(Q_values[0])\n",
        "    q2_vals.append(Q_values[1])\n",
        "    q3_vals.append(Q_values[2])\n",
        "  return actions, q1_vals, q2_vals, q3_vals"
      ],
      "metadata": {
        "id": "SsBp1Fu_Ywfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimistic_greedy_actions, og_q1_vals, og_q2_vals, og_q3_vals = optimistic_greedy(num_actions = 3)"
      ],
      "metadata": {
        "id": "nhKE5wTWYyve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d2 = {'Action1': og_q1_vals, 'Action2' : og_q2_vals, 'Action3' : og_q3_vals}\n",
        "df2 = pd.DataFrame(data = d2)"
      ],
      "metadata": {
        "id": "ODpmh6qVY3Y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f, axs = plt.subplots(1, 1, figsize=(10,5))\n",
        "plt.plot(df2.index, df2['Action1'], df2.index, df2['Action2'], df2.index, df2['Action3'])\n",
        "plt.title('Optimistic Greedy Approach', fontsize = 13)\n",
        "plt.xlabel('Time Steps', fontsize = 10)\n",
        "plt.ylabel('Estimated Q-values of the 3 actions', fontsize = 10)\n",
        "plt.legend(['Action1', 'Action2', 'Action3'])"
      ],
      "metadata": {
        "id": "YSS60m5_ZAqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SaPivDOcZGdO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}